{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Environment Setup\n",
    "# ----------------------------\n",
    "class SimpleEnvironment:\n",
    "    def __init__(self, goal_state=10, max_steps=20):\n",
    "        self.state = 0\n",
    "        self.goal_state = goal_state\n",
    "        self.max_steps = max_steps\n",
    "        self.steps = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = 0\n",
    "        self.steps = 0\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        self.state += action\n",
    "        self.steps += 1\n",
    "        reward = 1 if self.state == self.goal_state else -0.01\n",
    "        done = self.state == self.goal_state or self.steps >= self.max_steps\n",
    "        return self.state, reward, done\n",
    "\n",
    "# ----------------------------\n",
    "# Preprocessing\n",
    "# ----------------------------\n",
    "def preprocess_state(state):\n",
    "    return np.array([state / 10])  # Normalize by goal_state for simplicity\n",
    "\n",
    "# ----------------------------\n",
    "# Train-Test Split\n",
    "# ----------------------------\n",
    "def generate_data(env, num_episodes=100):\n",
    "    data = []\n",
    "    for _ in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode = []\n",
    "        while not done:\n",
    "            action = random.choice([-1, 1])\n",
    "            next_state, reward, done = env.step(action)\n",
    "            episode.append((state, action, reward, next_state))\n",
    "            state = next_state\n",
    "        data.append(episode)\n",
    "    split_idx = int(0.8 * len(data))\n",
    "    return data[:split_idx], data[split_idx:]\n",
    "\n",
    "# ----------------------------\n",
    "# Monte Carlo Tree Search (MCTS)\n",
    "# ----------------------------\n",
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.children = {}\n",
    "        self.visits = 0\n",
    "        self.value = 0\n",
    "\n",
    "    def is_fully_expanded(self):\n",
    "        return len(self.children) == 2  # actions: -1, 1\n",
    "\n",
    "    def best_child(self, c_param=1.4):\n",
    "        choices = [child for child in self.children.values()]\n",
    "        return max(choices, key=lambda x: x.value / (x.visits + 1e-4) + c_param * np.sqrt(np.log(self.visits + 1) / (x.visits + 1e-4)))\n",
    "\n",
    "def mcts_search(env, state, num_simulations=20):\n",
    "    root = MCTSNode(state)\n",
    "\n",
    "    for _ in range(num_simulations):\n",
    "        node = root\n",
    "        sim_env = SimpleEnvironment()\n",
    "        sim_env.state = state\n",
    "\n",
    "        # Selection & Expansion\n",
    "        while node.is_fully_expanded() and node.children:\n",
    "            node = node.best_child()\n",
    "            sim_env.step(node.state - node.parent.state)\n",
    "\n",
    "        if not node.is_fully_expanded():\n",
    "            action = random.choice([-1, 1])\n",
    "            next_state, reward, done = sim_env.step(action)\n",
    "            new_node = MCTSNode(next_state, parent=node)\n",
    "            node.children[action] = new_node\n",
    "            node = new_node\n",
    "\n",
    "        # Simulation\n",
    "        total_reward = 0\n",
    "        for _ in range(5):\n",
    "            if sim_env.state == sim_env.goal_state:\n",
    "                total_reward += 1\n",
    "                break\n",
    "            action = random.choice([-1, 1])\n",
    "            _, reward, done = sim_env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        # Backpropagation\n",
    "        while node:\n",
    "            node.visits += 1\n",
    "            node.value += total_reward\n",
    "            node = node.parent\n",
    "\n",
    "    return max(root.children.items(), key=lambda item: item[1].value / (item[1].visits + 1e-4))[0]\n",
    "\n",
    "# ----------------------------\n",
    "# Fine-Tune Model\n",
    "# ----------------------------\n",
    "def fine_tune(env, num_episodes=50):\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = mcts_search(env, state, num_simulations=10)  # Reduced simulations for faster performance\n",
    "            next_state, reward, done = env.step(action)\n",
    "            state = next_state\n",
    "\n",
    "# ----------------------------\n",
    "# Evaluation\n",
    "# ----------------------------\n",
    "def evaluate(env, num_episodes=20):\n",
    "    success_count = 0\n",
    "    for _ in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            action = mcts_search(env, state, num_simulations=5)\n",
    "            state, _, done = env.step(action)\n",
    "            steps += 1\n",
    "        if env.state == env.goal_state:\n",
    "            success_count += 1\n",
    "    print(f\"Success Rate: {success_count / num_episodes * 100:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# Deploy Policy\n",
    "# ----------------------------\n",
    "def deploy_policy(env):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    print(\"Deployment Run:\")\n",
    "    while not done:\n",
    "        action = mcts_search(env, state, num_simulations=5)\n",
    "        state, reward, done = env.step(action)\n",
    "        print(f\"State: {state}, Action: {action}, Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed State: [0.]\n",
      "Training Episodes: 80, Testing Episodes: 20\n",
      "Training base model...\n",
      "Evaluating model...\n",
      "Success Rate: 25.00%\n",
      "Deploying policy...\n",
      "Deployment Run:\n",
      "State: -1, Action: -1, Reward: -0.01\n",
      "State: -2, Action: -1, Reward: -0.01\n",
      "State: -3, Action: -1, Reward: -0.01\n",
      "State: -4, Action: -1, Reward: -0.01\n",
      "State: -3, Action: 1, Reward: -0.01\n",
      "State: -4, Action: -1, Reward: -0.01\n",
      "State: -3, Action: 1, Reward: -0.01\n",
      "State: -2, Action: 1, Reward: -0.01\n",
      "State: -1, Action: 1, Reward: -0.01\n",
      "State: -2, Action: -1, Reward: -0.01\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Main Flow\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    env = SimpleEnvironment(goal_state=5, max_steps=10)\n",
    "\n",
    "    # Preprocessing example\n",
    "    preprocessed_state = preprocess_state(env.reset())\n",
    "    print(f\"Preprocessed State: {preprocessed_state}\")\n",
    "\n",
    "    # Train-Test Split\n",
    "    train_data, test_data = generate_data(env)\n",
    "    print(f\"Training Episodes: {len(train_data)}, Testing Episodes: {len(test_data)}\")\n",
    "\n",
    "    # Train Base Model\n",
    "    print(\"Training base model...\")\n",
    "    fine_tune(env)\n",
    "\n",
    "    # Evaluate\n",
    "    print(\"Evaluating model...\")\n",
    "    evaluate(env)\n",
    "\n",
    "    # Deploy\n",
    "    print(\"Deploying policy...\")\n",
    "    deploy_policy(env)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
