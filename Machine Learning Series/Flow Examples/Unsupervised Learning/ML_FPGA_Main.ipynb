{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample transactions:\n",
      "[['A', 'F', 'C', 'E', 'D', 'B'], ['A', 'E', 'F', 'C', 'B', 'D'], ['A'], ['B', 'E'], ['A', 'E', 'B', 'C', 'D']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Generate Synthetic Data\n",
    "# ----------------------------\n",
    "# Define a list of items and create random transactions.\n",
    "items = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "n_transactions = 100\n",
    "transactions = []\n",
    "\n",
    "random.seed(42)  # For reproducibility\n",
    "\n",
    "for _ in range(n_transactions):\n",
    "    # Randomly choose a number of items per transaction (at least 1 item)\n",
    "    n_items = random.randint(1, len(items))\n",
    "    transaction = random.sample(items, n_items)\n",
    "    transactions.append(transaction)\n",
    "\n",
    "print(\"Sample transactions:\")\n",
    "print(transactions[:5])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded DataFrame (first 5 rows):\n",
      "       A      B      C      D      E      F\n",
      "0   True   True   True   True   True   True\n",
      "1   True   True   True   True   True   True\n",
      "2   True  False  False  False  False  False\n",
      "3  False   True  False  False   True  False\n",
      "4   True   True   True   True   True  False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Preprocessing\n",
    "# ----------------------------\n",
    "# Use TransactionEncoder to convert transactions into a one-hot encoded DataFrame.\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "print(\"One-hot encoded DataFrame (first 5 rows):\")\n",
    "print(df.head())\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 70 transactions\n",
      "Test set size: 30 transactions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Train-Test Split\n",
    "# ----------------------------\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "print(f\"Training set size: {train_df.shape[0]} transactions\")\n",
    "print(f\"Test set size: {test_df.shape[0]} transactions\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itemsets from training data:\n",
      "     support      itemsets\n",
      "0   0.642857           (B)\n",
      "1   0.614286           (A)\n",
      "2   0.585714           (C)\n",
      "3   0.571429           (D)\n",
      "4   0.557143           (E)\n",
      "5   0.485714           (F)\n",
      "6   0.400000        (A, B)\n",
      "7   0.442857        (C, B)\n",
      "8   0.385714        (A, C)\n",
      "9   0.314286     (A, C, B)\n",
      "10  0.428571        (D, B)\n",
      "11  0.385714        (C, D)\n",
      "12  0.385714        (A, D)\n",
      "13  0.328571     (C, D, B)\n",
      "14  0.300000     (A, D, B)\n",
      "15  0.457143        (C, E)\n",
      "16  0.442857        (E, B)\n",
      "17  0.400000        (A, E)\n",
      "18  0.357143        (D, E)\n",
      "19  0.385714     (C, E, B)\n",
      "20  0.342857     (A, C, E)\n",
      "21  0.328571     (A, E, B)\n",
      "22  0.300000  (A, C, E, B)\n",
      "23  0.314286     (D, E, B)\n",
      "24  0.314286     (C, D, E)\n",
      "25  0.300000     (A, D, E)\n",
      "26  0.371429        (F, B)\n",
      "27  0.357143        (D, F)\n",
      "28  0.314286        (A, F)\n",
      "29  0.300000        (E, F)\n",
      "30  0.300000        (C, F)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Train FP-Growth Model\n",
    "# ----------------------------\n",
    "# Set a minimum support threshold (e.g., 30% of training transactions).\n",
    "min_support = 0.3\n",
    "freq_itemsets = fpgrowth(train_df, min_support=min_support, use_colnames=True)\n",
    "print(\"Frequent itemsets from training data:\")\n",
    "print(freq_itemsets)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequent itemsets with training and test support:\n",
      "     support      itemsets  test_support\n",
      "0   0.642857           (B)      0.700000\n",
      "1   0.614286           (A)      0.766667\n",
      "2   0.585714           (C)      0.733333\n",
      "3   0.571429           (D)      0.633333\n",
      "4   0.557143           (E)      0.633333\n",
      "5   0.485714           (F)      0.566667\n",
      "6   0.400000        (A, B)      0.600000\n",
      "7   0.442857        (C, B)      0.566667\n",
      "8   0.385714        (A, C)      0.566667\n",
      "9   0.314286     (A, C, B)      0.500000\n",
      "10  0.428571        (D, B)      0.500000\n",
      "11  0.385714        (C, D)      0.533333\n",
      "12  0.385714        (A, D)      0.533333\n",
      "13  0.328571     (C, D, B)      0.466667\n",
      "14  0.300000     (A, D, B)      0.466667\n",
      "15  0.457143        (C, E)      0.533333\n",
      "16  0.442857        (E, B)      0.566667\n",
      "17  0.400000        (A, E)      0.566667\n",
      "18  0.357143        (D, E)      0.466667\n",
      "19  0.385714     (C, E, B)      0.466667\n",
      "20  0.342857     (A, C, E)      0.500000\n",
      "21  0.328571     (A, E, B)      0.500000\n",
      "22  0.300000  (A, C, E, B)      0.433333\n",
      "23  0.314286     (D, E, B)      0.433333\n",
      "24  0.314286     (C, D, E)      0.433333\n",
      "25  0.300000     (A, D, E)      0.433333\n",
      "26  0.371429        (F, B)      0.466667\n",
      "27  0.357143        (D, F)      0.433333\n",
      "28  0.314286        (A, F)      0.466667\n",
      "29  0.300000        (E, F)      0.400000\n",
      "30  0.300000        (C, F)      0.466667\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Evaluate on Test Data\n",
    "# ----------------------------\n",
    "# Define a helper function to compute support on a given DataFrame.\n",
    "def compute_support(dataframe, itemset):\n",
    "    # For a given itemset, compute the fraction of transactions in 'dataframe' that contain all items.\n",
    "    return dataframe[list(itemset)].all(axis=1).mean()\n",
    "\n",
    "# Calculate test support for each frequent itemset\n",
    "freq_itemsets['test_support'] = freq_itemsets['itemsets'].apply(lambda x: compute_support(test_df, x))\n",
    "print(\"Frequent itemsets with training and test support:\")\n",
    "print(freq_itemsets)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New transactions:\n",
      "[['E', 'B', 'C', 'A'], ['D', 'A', 'B', 'F', 'C', 'E'], ['C', 'E', 'F', 'D', 'A', 'B'], ['C', 'D', 'F', 'B', 'E'], ['B', 'F', 'D', 'C', 'E']]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Predict New Data\n",
    "# ----------------------------\n",
    "# Generate new random transactions.\n",
    "n_new_transactions = 5\n",
    "new_transactions = []\n",
    "\n",
    "for _ in range(n_new_transactions):\n",
    "    n_items = random.randint(1, len(items))\n",
    "    transaction = random.sample(items, n_items)\n",
    "    new_transactions.append(transaction)\n",
    "\n",
    "print(\"New transactions:\")\n",
    "print(new_transactions)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert new transactions into a one-hot encoded DataFrame using the same encoder.\n",
    "new_ary = te.transform(new_transactions)\n",
    "new_df = pd.DataFrame(new_ary, columns=te.columns_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on new transactions:\n",
      "{'transaction': ['A', 'B', 'C', 'E'], 'matching_frequent_itemsets': [frozenset({'B'}), frozenset({'A'}), frozenset({'C'}), frozenset({'E'}), frozenset({'A', 'B'}), frozenset({'C', 'B'}), frozenset({'A', 'C'}), frozenset({'A', 'C', 'B'}), frozenset({'C', 'E'}), frozenset({'E', 'B'}), frozenset({'A', 'E'}), frozenset({'C', 'E', 'B'}), frozenset({'A', 'C', 'E'}), frozenset({'A', 'E', 'B'}), frozenset({'A', 'C', 'E', 'B'})]}\n",
      "{'transaction': ['A', 'B', 'C', 'D', 'E', 'F'], 'matching_frequent_itemsets': [frozenset({'B'}), frozenset({'A'}), frozenset({'C'}), frozenset({'D'}), frozenset({'E'}), frozenset({'F'}), frozenset({'A', 'B'}), frozenset({'C', 'B'}), frozenset({'A', 'C'}), frozenset({'A', 'C', 'B'}), frozenset({'D', 'B'}), frozenset({'C', 'D'}), frozenset({'A', 'D'}), frozenset({'C', 'D', 'B'}), frozenset({'A', 'D', 'B'}), frozenset({'C', 'E'}), frozenset({'E', 'B'}), frozenset({'A', 'E'}), frozenset({'D', 'E'}), frozenset({'C', 'E', 'B'}), frozenset({'A', 'C', 'E'}), frozenset({'A', 'E', 'B'}), frozenset({'A', 'C', 'E', 'B'}), frozenset({'D', 'E', 'B'}), frozenset({'C', 'D', 'E'}), frozenset({'A', 'D', 'E'}), frozenset({'F', 'B'}), frozenset({'D', 'F'}), frozenset({'A', 'F'}), frozenset({'E', 'F'}), frozenset({'C', 'F'})]}\n",
      "{'transaction': ['A', 'B', 'C', 'D', 'E', 'F'], 'matching_frequent_itemsets': [frozenset({'B'}), frozenset({'A'}), frozenset({'C'}), frozenset({'D'}), frozenset({'E'}), frozenset({'F'}), frozenset({'A', 'B'}), frozenset({'C', 'B'}), frozenset({'A', 'C'}), frozenset({'A', 'C', 'B'}), frozenset({'D', 'B'}), frozenset({'C', 'D'}), frozenset({'A', 'D'}), frozenset({'C', 'D', 'B'}), frozenset({'A', 'D', 'B'}), frozenset({'C', 'E'}), frozenset({'E', 'B'}), frozenset({'A', 'E'}), frozenset({'D', 'E'}), frozenset({'C', 'E', 'B'}), frozenset({'A', 'C', 'E'}), frozenset({'A', 'E', 'B'}), frozenset({'A', 'C', 'E', 'B'}), frozenset({'D', 'E', 'B'}), frozenset({'C', 'D', 'E'}), frozenset({'A', 'D', 'E'}), frozenset({'F', 'B'}), frozenset({'D', 'F'}), frozenset({'A', 'F'}), frozenset({'E', 'F'}), frozenset({'C', 'F'})]}\n",
      "{'transaction': ['B', 'C', 'D', 'E', 'F'], 'matching_frequent_itemsets': [frozenset({'B'}), frozenset({'C'}), frozenset({'D'}), frozenset({'E'}), frozenset({'F'}), frozenset({'C', 'B'}), frozenset({'D', 'B'}), frozenset({'C', 'D'}), frozenset({'C', 'D', 'B'}), frozenset({'C', 'E'}), frozenset({'E', 'B'}), frozenset({'D', 'E'}), frozenset({'C', 'E', 'B'}), frozenset({'D', 'E', 'B'}), frozenset({'C', 'D', 'E'}), frozenset({'F', 'B'}), frozenset({'D', 'F'}), frozenset({'E', 'F'}), frozenset({'C', 'F'})]}\n",
      "{'transaction': ['B', 'C', 'D', 'E', 'F'], 'matching_frequent_itemsets': [frozenset({'B'}), frozenset({'C'}), frozenset({'D'}), frozenset({'E'}), frozenset({'F'}), frozenset({'C', 'B'}), frozenset({'D', 'B'}), frozenset({'C', 'D'}), frozenset({'C', 'D', 'B'}), frozenset({'C', 'E'}), frozenset({'E', 'B'}), frozenset({'D', 'E'}), frozenset({'C', 'E', 'B'}), frozenset({'D', 'E', 'B'}), frozenset({'C', 'D', 'E'}), frozenset({'F', 'B'}), frozenset({'D', 'F'}), frozenset({'E', 'F'}), frozenset({'C', 'F'})]}\n"
     ]
    }
   ],
   "source": [
    "# For each new transaction, find which frequent itemsets (from training) are contained in it.\n",
    "def find_frequent_itemsets_in_transaction(transaction, freq_itemsets_df):\n",
    "    matching_itemsets = []\n",
    "    for itemset in freq_itemsets_df['itemsets']:\n",
    "        # Check if all items in the frequent itemset are in the transaction.\n",
    "        if all(item in transaction for item in itemset):\n",
    "            matching_itemsets.append(itemset)\n",
    "    return matching_itemsets\n",
    "\n",
    "predictions = []\n",
    "for idx, row in new_df.iterrows():\n",
    "    # Convert boolean row back to list of items present in the transaction.\n",
    "    transaction_items = list(new_df.columns[row.values])\n",
    "    matching_itemsets = find_frequent_itemsets_in_transaction(transaction_items, freq_itemsets)\n",
    "    predictions.append({\n",
    "        'transaction': transaction_items,\n",
    "        'matching_frequent_itemsets': matching_itemsets\n",
    "    })\n",
    "\n",
    "print(\"Predictions on new transactions:\")\n",
    "for prediction in predictions:\n",
    "    print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
