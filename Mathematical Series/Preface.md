# Mathematics for Data Science
## Linear Algebra
### Basics
- Scalars
- Vectors
- Matrices
- Tensors
- Vector Spaces
- Linear Combinations and Span
- Linear Transformations
  
### Advanced
- Dot Product and Cross Product
- Norms and Distances
- Eigenvalues and Eigenvectors
- Matrix Decomposition
  - LU Decomposition
  - QR Decomposition
  - SV Decomposition
    
## Calculus
### Basic Concepts
- Limits and Continuity
- Differentiation
- Integration
- Fundamental Theorem of Calculus
  
### Multivariable Calculus
- Partial Derivatives
- Gradient, Divergent, and Curl
- Multiple Integrals
- Jacobian and Change of Variables
  
### Advanved Concepts
- Vector Calculus
  - Line Integrals
  - Surface Integrals
- Taylor Series and Approximation
- Optimization Techniques
  - Lagrange Multipliers
  - Constrained Optimization
- Differential Equations
  - Ordinary Differential Equations
  - Partial Differenrial Equations
  - Calculus of Variations

## Optimization
### Basic Concepts
- Objective Functions
- Convex and Non-Convex Functions
- Global vs. Local Minima/Maxima
- Gradient Descent (Basic)

### Constrained Optimization
- Linear Programming (LP)
- Quadratic Programming (QP)
- Lagrange Multipliers (Detailed)
- KKT Conditions (Karush-Kuhn-Tucker)

### Gradient-Based Variants
- Gradient Descents
  - SGD (Stochastic Gradient Descent)
  - Mini-Batch Gradient Descent
  - RMSProp (Root Mean Square Propagation)
- Momentum-Based Methods
  - Momentum
  - Nesterov Accelerated Gradient (NAG)
- Hybrid Variant (Gradient Descents & Momentum-based Methods)
  - Adam (Adaptive Moment Estimation)
- Newtonâ€™s Method and Quasi-Newton Methods

### Optimization for Machine Learning
- Stochastic Optimization
- Regularization Techniques
  - L2 (Ridge Regularization)
  - L1 (Lasso Regularization)
  - Elastic Net
  - Dropout
  - Early Stopping
- Hyperparameter Optimization
  - Grid Search
  - Random Search
  - Bayesian Optimization
  - Evolutionary Algorithms
    
### Advanced Optimization Topics
- Conjugate Gradient Method
- Trust-Region Methods
- Simulated Annealing
- Genetic Algorithms
- Coordinate Descent
  
### Optimization in Deep Learning
- Backpropagation and Gradient Flow
- Batch Normalization and Learning Rate Schedules
- Auto-Differentiation
